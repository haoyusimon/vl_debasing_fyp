{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9tObiU-qVgv"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ryansteed/ieat/blob/master/notebooks/experiments.ipynb)\n",
    "\n",
    "# Image GPT Bias\n",
    "**Image Embedding Association Test**\n",
    "\n",
    "Ryan Steed\n",
    "\n",
    "This script adapted from https://colab.research.google.com/github/apeguero1/image-gpt/blob/master/Transformers_Image_GPT.ipynb.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OoWYiUzT_lLs"
   },
   "source": [
    "## Download Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fJcpjSByxvhQ"
   },
   "source": [
    "## IATs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rv34zwKpSHSp"
   },
   "source": [
    "### Quick Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/h/haoyu/CLIP_debiasing/validation_exp/ieat\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "%cd ../../ieat\n",
    "\n",
    "model_sizes = [\"s\", \"m\", \"l\"] #small medium large, xl not available\n",
    "model_size = \"l\"\n",
    "models_dir = \"models\"\n",
    "color_clusters_dir = \"clusters\"\n",
    "n_px = 32\n",
    "depth = 152\n",
    "width = 3\n",
    "sk = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 562
    },
    "id": "vLl9AC5nSHSp",
    "outputId": "b5c5697e-0c30-496c-db1e-91452870f5c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# CLIP #\n",
      "Solve Closed Form Optimum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/02 02:05:04 PM: Extracting images from data/experiments/insect-flower/flower\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.59956909e-01 -2.32496005e-03  9.35011496e-04 ...  1.04442366e-02\n",
      "  -8.78277511e-04 -7.47815907e-03]\n",
      " [ 3.18337178e-04  9.70524516e-01  1.38072792e-03 ... -4.56906793e-03\n",
      "   8.44344805e-03  1.18974976e-03]\n",
      " [ 2.84981244e-03  2.50264471e-03  9.82401554e-01 ...  1.10640397e-03\n",
      "  -2.00579760e-03  7.38100268e-04]\n",
      " ...\n",
      " [ 8.24780356e-03 -1.03855726e-03 -1.25846139e-03 ...  9.71880434e-01\n",
      "   1.81147438e-03 -1.07559079e-02]\n",
      " [ 3.81824493e-03  5.70452748e-03 -1.40284385e-03 ...  1.70556081e-03\n",
      "   9.76014736e-01 -3.36195994e-03]\n",
      " [-8.65486180e-03  9.34662361e-04 -1.53460377e-03 ... -6.47994357e-03\n",
      "  -8.83678454e-03  9.61712814e-01]]\n",
      "## Insect-Flower ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/02 02:05:13 PM: Extracting images from data/experiments/insect-flower/insect\n",
      "04/02 02:05:17 PM: Extracting texts from data/experiments/valence/pleasant\n",
      "/home/h/haoyu/CLIP_debiasing/validation_exp/ieat/ieat/clip_models.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  text_embeddings = torch.tensor(text_embeddings).float().to(self.device)\n",
      "04/02 02:05:17 PM: Extracting texts from data/experiments/valence/unpleasant\n",
      "04/02 02:05:18 PM: Extracting images from data/experiments/weapon/white\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Weapon ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/02 02:05:18 PM: Extracting images from data/experiments/weapon/black\n",
      "04/02 02:05:19 PM: Extracting texts from data/experiments/weapon/tool\n",
      "/home/h/haoyu/CLIP_debiasing/validation_exp/ieat/ieat/clip_models.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  text_embeddings = torch.tensor(text_embeddings).float().to(self.device)\n",
      "04/02 02:05:19 PM: Extracting texts from data/experiments/weapon/weapon\n",
      "04/02 02:05:19 PM: Equalities contributed 1/924 to p-value\n",
      "04/02 02:05:19 PM: Extracting images from data/experiments/native/euro\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Native ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/02 02:05:20 PM: Extracting images from data/experiments/native/native\n",
      "04/02 02:05:20 PM: Extracting texts from data/experiments/native/us\n",
      "/home/h/haoyu/CLIP_debiasing/validation_exp/ieat/ieat/clip_models.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  text_embeddings = torch.tensor(text_embeddings).float().to(self.device)\n",
      "04/02 02:05:20 PM: Extracting texts from data/experiments/native/world\n",
      "04/02 02:05:20 PM: Extracting images from data/experiments/weight/thin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Weight ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/02 02:05:21 PM: Extracting images from data/experiments/weight/fat\n",
      "04/02 02:05:22 PM: Extracting texts from data/experiments/valence/pleasant\n",
      "/home/h/haoyu/CLIP_debiasing/validation_exp/ieat/ieat/clip_models.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  text_embeddings = torch.tensor(text_embeddings).float().to(self.device)\n",
      "04/02 02:05:22 PM: Extracting texts from data/experiments/valence/unpleasant\n",
      "04/02 02:05:22 PM: Extracting images from data/experiments/skin-tone/light\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Skin-Tone ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/02 02:05:23 PM: Extracting images from data/experiments/skin-tone/dark\n",
      "04/02 02:05:23 PM: Extracting texts from data/experiments/valence/pleasant\n",
      "/home/h/haoyu/CLIP_debiasing/validation_exp/ieat/ieat/clip_models.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  text_embeddings = torch.tensor(text_embeddings).float().to(self.device)\n",
      "04/02 02:05:23 PM: Extracting texts from data/experiments/valence/unpleasant\n",
      "04/02 02:05:24 PM: Equalities contributed 1/3432 to p-value\n",
      "04/02 02:05:24 PM: Extracting images from data/experiments/disabled/disabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Disability ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/02 02:05:24 PM: Extracting images from data/experiments/disabled/abled\n",
      "04/02 02:05:24 PM: Extracting texts from data/experiments/valence/pleasant\n",
      "/home/h/haoyu/CLIP_debiasing/validation_exp/ieat/ieat/clip_models.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  text_embeddings = torch.tensor(text_embeddings).float().to(self.device)\n",
      "04/02 02:05:24 PM: Extracting texts from data/experiments/valence/unpleasant\n",
      "04/02 02:05:24 PM: Equalities contributed 1/70 to p-value\n",
      "04/02 02:05:24 PM: Extracting images from data/experiments/sexuality/gay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Sexuality ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/02 02:05:25 PM: Extracting images from data/experiments/sexuality/straight\n",
      "04/02 02:05:26 PM: Extracting texts from data/experiments/valence/pleasant\n",
      "/home/h/haoyu/CLIP_debiasing/validation_exp/ieat/ieat/clip_models.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  text_embeddings = torch.tensor(text_embeddings).float().to(self.device)\n",
      "04/02 02:05:26 PM: Extracting texts from data/experiments/valence/unpleasant\n",
      "04/02 02:05:26 PM: Extracting images from data/experiments/race/european-american\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Race ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/02 02:05:27 PM: Extracting images from data/experiments/race/african-american\n",
      "04/02 02:05:27 PM: Extracting texts from data/experiments/valence/pleasant\n",
      "/home/h/haoyu/CLIP_debiasing/validation_exp/ieat/ieat/clip_models.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  text_embeddings = torch.tensor(text_embeddings).float().to(self.device)\n",
      "04/02 02:05:27 PM: Extracting texts from data/experiments/valence/unpleasant\n",
      "04/02 02:05:28 PM: Equalities contributed 1/924 to p-value\n",
      "04/02 02:05:28 PM: Extracting images from data/experiments/arab-muslim/other-people\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Arab-Muslim ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/02 02:05:29 PM: Extracting images from data/experiments/arab-muslim/arab-muslim\n",
      "04/02 02:05:30 PM: Extracting texts from data/experiments/valence/pleasant\n",
      "/home/h/haoyu/CLIP_debiasing/validation_exp/ieat/ieat/clip_models.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  text_embeddings = torch.tensor(text_embeddings).float().to(self.device)\n",
      "04/02 02:05:30 PM: Extracting texts from data/experiments/valence/unpleasant\n",
      "04/02 02:05:30 PM: Extracting images from data/experiments/age/young\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Age ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/02 02:05:31 PM: Extracting images from data/experiments/age/old\n",
      "04/02 02:05:31 PM: Extracting texts from data/experiments/valence/pleasant\n",
      "/home/h/haoyu/CLIP_debiasing/validation_exp/ieat/ieat/clip_models.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  text_embeddings = torch.tensor(text_embeddings).float().to(self.device)\n",
      "04/02 02:05:31 PM: Extracting texts from data/experiments/valence/unpleasant\n",
      "04/02 02:05:31 PM: Equalities contributed 1/924 to p-value\n",
      "04/02 02:05:31 PM: Extracting images from data/experiments/gender/male\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Gender-Science ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/02 02:05:35 PM: Extracting images from data/experiments/gender/female\n",
      "04/02 02:05:38 PM: Extracting texts from data/experiments/gender/science\n",
      "/home/h/haoyu/CLIP_debiasing/validation_exp/ieat/ieat/clip_models.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  text_embeddings = torch.tensor(text_embeddings).float().to(self.device)\n",
      "04/02 02:05:39 PM: Extracting texts from data/experiments/gender/liberal-arts\n",
      "04/02 02:05:39 PM: Extracting images from data/experiments/gender/male\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Gender-Career ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/02 02:05:42 PM: Extracting images from data/experiments/gender/female\n",
      "04/02 02:05:46 PM: Extracting texts from data/experiments/gender/career\n",
      "/home/h/haoyu/CLIP_debiasing/validation_exp/ieat/ieat/clip_models.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  text_embeddings = torch.tensor(text_embeddings).float().to(self.device)\n",
      "04/02 02:05:46 PM: Extracting texts from data/experiments/gender/family\n"
     ]
    }
   ],
   "source": [
    "from ieat.api import test_all\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "results = test_all(\n",
    "    {\n",
    "        # 'igpt-logit': (model_size,models_dir,color_clusters_dir,n_px),\n",
    "        # 'igpt': (model_size,models_dir,color_clusters_dir,n_px),\n",
    "        # 'simclr': (depth, width, sk),\n",
    "        'CLIP': (224,)\n",
    "    },\n",
    "    # verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "fv2Node4SHSs"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>d</th>\n",
       "      <th>p</th>\n",
       "      <th>n_t</th>\n",
       "      <th>n_a</th>\n",
       "      <th>sig</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gender-Science</th>\n",
       "      <th>CLIP</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>science</td>\n",
       "      <td>liberal-arts</td>\n",
       "      <td>0.563356</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>40</td>\n",
       "      <td>21</td>\n",
       "      <td>***</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender-Career</th>\n",
       "      <th>CLIP</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>career</td>\n",
       "      <td>family</td>\n",
       "      <td>0.733787</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>40</td>\n",
       "      <td>21</td>\n",
       "      <td>***</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        X       Y        A             B         d       p  \\\n",
       "Gender-Science CLIP  male  female  science  liberal-arts  0.563356  0.0045   \n",
       "Gender-Career  CLIP  male  female   career        family  0.733787  0.0004   \n",
       "\n",
       "                    n_t n_a  sig  \n",
       "Gender-Science CLIP  40  21  ***  \n",
       "Gender-Career  CLIP  40  21  ***  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame(results).transpose()\n",
    "results_df.columns = [\"X\", \"Y\", \"A\", \"B\", \"d\", \"p\", \"n_t\", \"n_a\"]\n",
    "for c in results_df.columns[:4]:\n",
    "    results_df[c] = results_df[c].str.split(\"/\").str[-1]\n",
    "results_df[\"sig\"] = \"\"\n",
    "for l in [0.10, 0.05, 0.01]:\n",
    "    results_df.sig[results_df.p < l] += \"*\"\n",
    "intersectional = results_df.index.get_level_values(0).str.contains(\"Intersectional\")\n",
    "gender = results_df.index.get_level_values(0).str.contains(\"Gender\")\n",
    "results_df[gender]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "9x5qXqGrSHSu"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$X$</th>\n",
       "      <th>$Y$</th>\n",
       "      <th>$A$</th>\n",
       "      <th>$B$</th>\n",
       "      <th>$n_t$</th>\n",
       "      <th>$n_a$</th>\n",
       "      <th>Model</th>\n",
       "      <th>$d$</th>\n",
       "      <th>$p$</th>\n",
       "      <th>IAT $d$</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [$X$, $Y$, $A$, $B$, $n_t$, $n_a$, Model, $d$, $p$, IAT $d$]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$X$</th>\n",
       "      <th>$Y$</th>\n",
       "      <th>$A$</th>\n",
       "      <th>$B$</th>\n",
       "      <th>$n_t$</th>\n",
       "      <th>$n_a$</th>\n",
       "      <th>$d$</th>\n",
       "      <th>$p$</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [$X$, $Y$, $A$, $B$, $n_t$, $n_a$, $d$, $p$]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate latex table output\n",
    "experiments = (\n",
    "    \"Insect-Flower\",\n",
    "    \"Gender-Science\",\n",
    "    \"Gender-Career\",\n",
    "    \"Skin-Tone\",\n",
    "    \"Race\",\n",
    "    \"Weapon\",\n",
    "    \"Weapon (Modern)\",\n",
    "    \"Native\",\n",
    "    \"Asian\",\n",
    "    \"Weight\",\n",
    "    \"Religion\",\n",
    "    \"Sexuality\",\n",
    "    \"Disability\",\n",
    "    \"Arab-Muslim\",\n",
    "    \"Age\"\n",
    ")\n",
    "latex_df = results_df\n",
    "latex_df.index = latex_df.index.set_names([\"Test\", \"Model\"])\n",
    "latex_df = latex_df.sort_index(level=[\"Test\", \"Model\"])\n",
    "results_df.to_csv(\"output/results-image-text-B-16-two-sided_prompt_age.csv\")\n",
    "\n",
    "experiments += tuple(results_df.index.get_level_values(\"Test\")[results_df.index.get_level_values(\"Test\").str.contains(\"Intersectional\")])\n",
    "def round(s, i='{0:.2f}', sci=False):\n",
    "    return s.apply(\n",
    "        lambda p: i.format(p) if not sci else (\n",
    "            \"$<10^{-3}$\" if p<=0.001 else\n",
    "            \"$<10^{-2}$\" if p<=0.01 else\n",
    "            i.format(p)\n",
    "        )\n",
    "    ).astype(str)\n",
    "latex_df.to_csv(\"temp.csv\")\n",
    "latex_df[\"d\"] = round(latex_df.d) #+ latex_df.sig.astype(str)\n",
    "latex_df[\"p\"] = round(latex_df.p, sci=True)\n",
    "latex_df = latex_df.drop(columns=[\"sig\"])\n",
    "\n",
    "original_results = {\n",
    "    \"Age\": 1.23,\n",
    "    \"Arab-Muslim\": 0.33,\n",
    "    \"Asian\": 0.62,\n",
    "    \"Disability\": 1.05,\n",
    "    \"Gender-Career\": 1.10,\n",
    "    \"Gender-Science\": 0.93,\n",
    "    \"Insect-Flower\": 1.35,\n",
    "    \"Native\": 0.46,\n",
    "    \"Race\": 0.86,\n",
    "    \"Religion\": -0.34,\n",
    "    \"Sexuality\": 0.74,\n",
    "    \"Skin-Tone\": 0.73,\n",
    "    \"Weapon\": 1.00,\n",
    "    \"Weight\": 1.83\n",
    "}\n",
    "original = pd.DataFrame.from_dict(original_results, orient='index', columns=[\"IAT $d$\"])\n",
    "latex_df.columns = [f\"${col}$\" for col in latex_df.columns]\n",
    "original.index = original.index.set_names([\"Test\"])\n",
    "latex_df = latex_df.join(original)\n",
    "\n",
    "def models(df, *keys):\n",
    "    return df[\"Model\"].isin(keys)\n",
    "\n",
    "# some filters\n",
    "latex_df = latex_df.reset_index(level=\"Model\")\n",
    "main_experiment = latex_df.index.get_level_values(\"Test\").isin(experiments)\n",
    "intersectional = latex_df.index.get_level_values(\"Test\").str.contains(\"Intersectional\")\n",
    "\n",
    "# some formatters\n",
    "def color_d(x):\n",
    "    d = float(x)\n",
    "    x = str(x)\n",
    "    return \\\n",
    "        f\"\\cellcolor{{d_large}}{x}\" if d > 0.8 else\\\n",
    "        f\"\\cellcolor{{d_medium}}{x}\" if d > 0.5 else\\\n",
    "        f\"\\cellcolor{{d_small}}{x}\" if d > 0.2 else\\\n",
    "        x\n",
    "\n",
    "def model_fmt(x):\n",
    "    return \"iGPT\" if x == \"igpt\" else \"iGPT Logit\" if x == \"igpt-logit\" else \"SimCLR\" if x == \"SimCLR\" else \"CLIP\"\n",
    "\n",
    "class FMT:\n",
    "    def __init__(self):\n",
    "        self.last = None\n",
    "        self.i = 0\n",
    "        self.noskips = True\n",
    "    def test_fmt(self, x):\n",
    "        if self.noskips and x.startswith(\"Intersectional\"):\n",
    "            b = x.strip(\"Intersectional-\").split(\"-\")\n",
    "            i = \"-\".join(b[:-1])\n",
    "            return f\"{i} ({b[-1]})\"\n",
    "        if x == self.last:\n",
    "            return \"\"\n",
    "        self.last = x\n",
    "        if x in [\"Age\", \"Disability\", \"Race\", \"Skin-Tone\", \"Weight\"]:\n",
    "            x += \"\\textsuperscript{\\textdagger}\"\n",
    "        if x in [\"Asian\", \"Native\", \"Weapon\"]:\n",
    "            x += \"\\textsuperscript{$\\mathsection$}\"\n",
    "        return x\n",
    "    def category_format(self, x):\n",
    "        if self.noskips and x == self.last and self.i < 1 and x not in [\"white-male\", \"black-male\", \"white-female\", \"black-female\"]:\n",
    "            self.i += 1\n",
    "            return \"\"\n",
    "        else:\n",
    "            self.last = x\n",
    "            self.i = 0\n",
    "        x = x.capitalize()\n",
    "        cats_fmt = {\n",
    "            \"Other-people\": \"Other\",\n",
    "            \"Arab-muslim\": \"Arab-Muslim\",\n",
    "            \"European-american\": \"European American\",\n",
    "            \"Asian-american\": \"Asian American\",\n",
    "            \"Euro\": \"European American\",\n",
    "            \"Native\": \"Native American\",\n",
    "            \"African-american\": \"African American\",\n",
    "            \"Liberal-arts\": \"Liberal Arts\",\n",
    "            \"Us\": \"U.S.\",\n",
    "            \"Tool-modern\": \"Tool\",\n",
    "            \"Weapon-modern\": \"Weapon\",\n",
    "            \"Black-female\": \"Black Female\",\n",
    "            \"Black-male\": \"Black Male\",\n",
    "            \"White-female\": \"White Female\",\n",
    "            \"White-male\": \"White Male\"\n",
    "        }\n",
    "        return cats_fmt.get(x) if cats_fmt.get(x) is not None else x\n",
    "    def n_fmt(self, x):\n",
    "        if self.noskips and x == self.last and self.i < 1:\n",
    "            self.i += 1\n",
    "            return \"\"\n",
    "        else:\n",
    "            self.last = x\n",
    "            self.i = 0\n",
    "            return x\n",
    "\n",
    "fmter = FMT()\n",
    "    \n",
    "# main results\n",
    "cols = [\"$X$\", \"$Y$\", \"$A$\", \"$B$\", \"$n_t$\", \"$n_a$\", \"Model\", \"$d$\", \"$p$\", \"IAT $d$\"]\n",
    "results_table = latex_df[main_experiment & ~intersectional & models(latex_df, \"igpt\", \"simclr\")][cols]\n",
    "display(results_table)\n",
    "results_table.index = [fmter.test_fmt(x) for x in results_table.index]\n",
    "results_table.to_latex('output/results.tex', escape=False, na_rep=\"N/A\",\n",
    "    formatters={\n",
    "        \"$d$\": color_d, \n",
    "        \"IAT $d$\": color_d,\n",
    "        \"$X$\": fmter.category_format,\n",
    "        \"$Y$\": fmter.category_format,\n",
    "        \"$A$\": fmter.category_format,\n",
    "        \"$B$\": fmter.category_format,\n",
    "        \"Model\": model_fmt,\n",
    "        \"$n_t$\": fmter.n_fmt,\n",
    "        \"$n_a$\": fmter.n_fmt\n",
    "    }\n",
    ")\n",
    "\n",
    "# logit results\n",
    "cols = [c for c in cols if c not in (\"Model\", \"IAT $d$\")]\n",
    "logit_table = latex_df[main_experiment & ~intersectional & models(latex_df, \"igpt-logit\")][cols]\n",
    "display(logit_table)\n",
    "logit_table.index = [fmter.test_fmt(x) for x in logit_table.index]\n",
    "fmter.noskips = False\n",
    "logit_table.to_latex('output/logit.tex', escape=False,\n",
    "    formatters={\n",
    "        \"$d$\": color_d, \n",
    "        \"$X$\": fmter.category_format,\n",
    "        \"$Y$\": fmter.category_format,\n",
    "        \"$A$\": fmter.category_format,\n",
    "        \"$B$\": fmter.category_format,\n",
    "        \"$n_t$\": fmter.n_fmt,\n",
    "        \"$n_a$\": fmter.n_fmt\n",
    "    }\n",
    ")\n",
    "\n",
    "# intersectional results\n",
    "# cols = [\"$X$\", \"$Y$\", \"$A$\", \"$B$\", \"$n_t$\", \"$n_a$\", \"$d$\", \"$p$\"]\n",
    "# fmter.noskips = True\n",
    "# intersectional_table = latex_df[main_experiment & intersectional & models(latex_df, \"igpt\")][cols]\n",
    "# display(intersectional_table)\n",
    "# intersectional_table.index = [fmter.test_fmt(x) for x in intersectional_table.index]\n",
    "# intersectional_table.to_latex('output/intersectional.tex', escape=False, \n",
    "#     formatters={\n",
    "#         \"$d$\": color_d, \n",
    "#         \"$X$\": fmter.category_format,\n",
    "#         \"$Y$\": fmter.category_format,\n",
    "#         \"$A$\": fmter.category_format,\n",
    "#         \"$B$\": fmter.category_format,\n",
    "#         # \"Test\": intersectional_fmt\n",
    "# #         \"$n_t$\": fmter.n_fmt,\n",
    "# #         \"$n_a$\": fmter.n_fmt\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# table of iats w/ categories\n",
    "# iats_table = latex_df.groupby(\"Test\").head(1)\\\n",
    "#     .drop(columns=[\"$d$\", \"$p$\", \"$n_t$\", \"$n_a$\", \"Model\"])\n",
    "# display(iats_table)\n",
    "# iats_table.to_latex('output/iats.tex', escape=False, multirow=True)\n",
    "\n",
    "# stimuli table\n",
    "stimuli = pd.read_csv(\"data/stimuli.csv\")\n",
    "stimuli.dropna(axis=0, subset=[\"Word\", \"Source\"])\\\n",
    "    .drop(columns=\"Collected (N=n)\").set_index([\"IAT\", \"Category\"]).to_latex(\"output/stimuli.tex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized Insect-Flower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "test() missing 1 required positional argument: 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9c5f366f1e80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mieat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m print(test(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;34m'data/experiments/insect-flower/flower'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data/experiments/insect-flower/insect'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m'data/experiments/valence/pleasant'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data/experiments/valence/unpleasant'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: test() missing 1 required positional argument: 'name'"
     ]
    }
   ],
   "source": [
    "from ieat.api import test\n",
    "\n",
    "print(test(\n",
    "    'data/experiments/insect-flower/flower', 'data/experiments/insect-flower/insect', \n",
    "    'data/experiments/valence/pleasant', 'data/experiments/valence/unpleasant',\n",
    "    model_type='igpt',\n",
    "    model_params=(model_size,models_dir,color_clusters_dir,n_px),\n",
    "    randomized=False\n",
    "))\n",
    "ps = []\n",
    "for i in range(1000):\n",
    "    if i % 10 == 0: print(i if i % 50 == 0 else \".\", end=\" \")\n",
    "    _, p = test(\n",
    "        'data/experiments/insect-flower/flower', 'data/experiments/insect-flower/insect', \n",
    "        'data/experiments/valence/pleasant', 'data/experiments/valence/unpleasant',\n",
    "        model_type='igpt',\n",
    "        model_params=(model_size,models_dir,color_clusters_dir,n_px),\n",
    "        randomized=True\n",
    "    )\n",
    "    ps.append(p)\n",
    "print(\"Proportion of p-values under 0.1: \", len([p for p in ps if p < 0.1])/1000.)\n",
    "print(\"Proportion of p-values under 0.01: \", len([p for p in ps if p < 0.01])/1000.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Extraction Model\n",
    "Inspired by [Peiyang He](https://github.com/PeiyangHe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Insect-Flower ##\n",
      "## Weapon ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-21 12:56:36,707 [12199] WARNING  root:225: [JupyterRequire] Equalities contributed 1/924 to p-value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Weapon (Modern) ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-21 12:56:41,511 [12199] WARNING  root:225: [JupyterRequire] Equalities contributed 1/924 to p-value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Native ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-21 12:56:45,526 [12199] WARNING  root:225: [JupyterRequire] Equalities contributed 3/10000 to p-value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Asian ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-21 12:56:49,187 [12199] WARNING  root:225: [JupyterRequire] Equalities contributed 1/924 to p-value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Weight ##\n",
      "## Skin-Tone ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-21 12:57:28,141 [12199] WARNING  root:225: [JupyterRequire] Equalities contributed 1/3432 to p-value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Disability ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-21 12:57:46,296 [12199] WARNING  root:225: [JupyterRequire] Equalities contributed 1/70 to p-value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## President - Kennedy vs. Trump ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-21 12:58:05,223 [12199] WARNING  root:225: [JupyterRequire] Equalities contributed 1/924 to p-value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## President - B. Clinton vs. Trump ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-21 12:58:23,949 [12199] WARNING  root:225: [JupyterRequire] Equalities contributed 1/924 to p-value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## President - Bush vs. Trump ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-21 12:58:42,678 [12199] WARNING  root:225: [JupyterRequire] Equalities contributed 1/924 to p-value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## President - Lincoln vs. Trump ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-21 12:59:01,428 [12199] WARNING  root:225: [JupyterRequire] Equalities contributed 1/924 to p-value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Religion ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-21 12:59:20,624 [12199] WARNING  root:225: [JupyterRequire] Equalities contributed 1/3432 to p-value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Sexuality ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-21 12:59:40,466 [12199] WARNING  root:225: [JupyterRequire] Equalities contributed 1/10000 to p-value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Race ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-21 12:59:59,529 [12199] WARNING  root:225: [JupyterRequire] Equalities contributed 1/924 to p-value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Arab-Muslim ##\n",
      "## Age ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-21 13:03:20,815 [12199] WARNING  root:225: [JupyterRequire] Equalities contributed 1/924 to p-value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Gender-Science ##\n",
      "## Gender-Career ##\n",
      "## Intersectional-Gender-Science-MF ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-21 13:04:19,959 [12199] WARNING  root:225: [JupyterRequire] Equalities contributed 1/10000 to p-value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Intersectional-Gender-Science-WMBM ##\n",
      "## Intersectional-Gender-Science-WMBF ##\n",
      "## Intersectional-Gender-Science-WMWF ##\n",
      "## Intersectional-Gender-Career-MF ##\n",
      "## Intersectional-Gender-Career-WMBM ##\n",
      "## Intersectional-Gender-Career-WMBF ##\n",
      "## Intersectional-Gender-Career-WMWF ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-21 13:06:03,031 [12199] WARNING  root:225: [JupyterRequire] Equalities contributed 1/10000 to p-value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Intersectional-Valence-BW ##\n",
      "## Intersectional-Valence-WMBM ##\n",
      "## Intersectional-Valence-WMBF ##\n",
      "## Intersectional-Valence-WMWF ##\n",
      "## Intersectional-Valence-WFBM ##\n",
      "## Intersectional-Valence-BFBM ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-21 13:08:30,667 [12199] WARNING  root:225: [JupyterRequire] Equalities contributed 1/10000 to p-value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Intersectional-Valence-WFBF ##\n",
      "## Intersectional-Valence-FM ##\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/experiments/insect-flower/flower</td>\n",
       "      <td>data/experiments/insect-flower/insect</td>\n",
       "      <td>data/experiments/valence/pleasant</td>\n",
       "      <td>data/experiments/valence/unpleasant</td>\n",
       "      <td>-0.095075</td>\n",
       "      <td>0.647200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/experiments/weapon/white</td>\n",
       "      <td>data/experiments/weapon/black</td>\n",
       "      <td>data/experiments/weapon/tool</td>\n",
       "      <td>data/experiments/weapon/weapon</td>\n",
       "      <td>0.261615</td>\n",
       "      <td>0.318182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/experiments/weapon/white</td>\n",
       "      <td>data/experiments/weapon/black</td>\n",
       "      <td>data/experiments/weapon/tool-modern</td>\n",
       "      <td>data/experiments/weapon/weapon-modern</td>\n",
       "      <td>-0.321774</td>\n",
       "      <td>0.704545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/experiments/native/euro</td>\n",
       "      <td>data/experiments/native/native</td>\n",
       "      <td>data/experiments/native/us</td>\n",
       "      <td>data/experiments/native/world</td>\n",
       "      <td>0.106602</td>\n",
       "      <td>0.424100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/experiments/asian/european-american</td>\n",
       "      <td>data/experiments/asian/asian-american</td>\n",
       "      <td>data/experiments/asian/american</td>\n",
       "      <td>data/experiments/asian/foreign</td>\n",
       "      <td>-0.326956</td>\n",
       "      <td>0.737013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>data/experiments/weight/thin</td>\n",
       "      <td>data/experiments/weight/fat</td>\n",
       "      <td>data/experiments/valence/pleasant</td>\n",
       "      <td>data/experiments/valence/unpleasant</td>\n",
       "      <td>-0.175856</td>\n",
       "      <td>0.652800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>data/experiments/skin-tone/light</td>\n",
       "      <td>data/experiments/skin-tone/dark</td>\n",
       "      <td>data/experiments/valence/pleasant</td>\n",
       "      <td>data/experiments/valence/unpleasant</td>\n",
       "      <td>0.138021</td>\n",
       "      <td>0.400058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>data/experiments/disabled/disabled</td>\n",
       "      <td>data/experiments/disabled/abled</td>\n",
       "      <td>data/experiments/valence/pleasant</td>\n",
       "      <td>data/experiments/valence/unpleasant</td>\n",
       "      <td>-0.001860</td>\n",
       "      <td>0.514286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>data/experiments/presidents/kennedy</td>\n",
       "      <td>data/experiments/presidents/trump</td>\n",
       "      <td>data/experiments/valence/pleasant</td>\n",
       "      <td>data/experiments/valence/unpleasant</td>\n",
       "      <td>-0.006637</td>\n",
       "      <td>0.510823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>data/experiments/presidents/clinton</td>\n",
       "      <td>data/experiments/presidents/trump</td>\n",
       "      <td>data/experiments/valence/pleasant</td>\n",
       "      <td>data/experiments/valence/unpleasant</td>\n",
       "      <td>0.140065</td>\n",
       "      <td>0.325758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>data/experiments/presidents/bush</td>\n",
       "      <td>data/experiments/presidents/trump</td>\n",
       "      <td>data/experiments/valence/pleasant</td>\n",
       "      <td>data/experiments/valence/unpleasant</td>\n",
       "      <td>0.140525</td>\n",
       "      <td>0.358225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>data/experiments/presidents/lincoln</td>\n",
       "      <td>data/experiments/presidents/trump</td>\n",
       "      <td>data/experiments/valence/pleasant</td>\n",
       "      <td>data/experiments/valence/unpleasant</td>\n",
       "      <td>-0.173634</td>\n",
       "      <td>0.637446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>data/experiments/religion/christianity</td>\n",
       "      <td>data/experiments/religion/judaism</td>\n",
       "      <td>data/experiments/valence/pleasant</td>\n",
       "      <td>data/experiments/valence/unpleasant</td>\n",
       "      <td>-0.472518</td>\n",
       "      <td>0.805361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>data/experiments/sexuality/gay</td>\n",
       "      <td>data/experiments/sexuality/straight</td>\n",
       "      <td>data/experiments/valence/pleasant</td>\n",
       "      <td>data/experiments/valence/unpleasant</td>\n",
       "      <td>-0.044957</td>\n",
       "      <td>0.535600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>data/experiments/race/european-american</td>\n",
       "      <td>data/experiments/race/african-american</td>\n",
       "      <td>data/experiments/valence/pleasant</td>\n",
       "      <td>data/experiments/valence/unpleasant</td>\n",
       "      <td>-0.466431</td>\n",
       "      <td>0.778139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>data/experiments/arab-muslim/other-people</td>\n",
       "      <td>data/experiments/arab-muslim/arab-muslim</td>\n",
       "      <td>data/experiments/valence/pleasant</td>\n",
       "      <td>data/experiments/valence/unpleasant</td>\n",
       "      <td>0.218567</td>\n",
       "      <td>0.318200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>data/experiments/age/young</td>\n",
       "      <td>data/experiments/age/old</td>\n",
       "      <td>data/experiments/valence/pleasant</td>\n",
       "      <td>data/experiments/valence/unpleasant</td>\n",
       "      <td>0.050492</td>\n",
       "      <td>0.468615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>data/experiments/gender/male</td>\n",
       "      <td>data/experiments/gender/female</td>\n",
       "      <td>data/experiments/gender/science</td>\n",
       "      <td>data/experiments/gender/liberal-arts</td>\n",
       "      <td>0.049749</td>\n",
       "      <td>0.411600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>data/experiments/gender/male</td>\n",
       "      <td>data/experiments/gender/female</td>\n",
       "      <td>data/experiments/gender/career</td>\n",
       "      <td>data/experiments/gender/family</td>\n",
       "      <td>-0.028811</td>\n",
       "      <td>0.555200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>data/experiments/intersectional/male</td>\n",
       "      <td>data/experiments/intersectional/female</td>\n",
       "      <td>data/experiments/gender/science</td>\n",
       "      <td>data/experiments/gender/liberal-arts</td>\n",
       "      <td>-0.056506</td>\n",
       "      <td>0.604600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>data/experiments/intersectional/white-male</td>\n",
       "      <td>data/experiments/intersectional/black-male</td>\n",
       "      <td>data/experiments/gender/science</td>\n",
       "      <td>data/experiments/gender/liberal-arts</td>\n",
       "      <td>-0.246323</td>\n",
       "      <td>0.776700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>data/experiments/intersectional/white-male</td>\n",
       "      <td>data/experiments/intersectional/black-female</td>\n",
       "      <td>data/experiments/gender/science</td>\n",
       "      <td>data/experiments/gender/liberal-arts</td>\n",
       "      <td>0.044464</td>\n",
       "      <td>0.447700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>data/experiments/intersectional/white-male</td>\n",
       "      <td>data/experiments/intersectional/white-female</td>\n",
       "      <td>data/experiments/gender/science</td>\n",
       "      <td>data/experiments/gender/liberal-arts</td>\n",
       "      <td>0.238102</td>\n",
       "      <td>0.228700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>data/experiments/intersectional/male</td>\n",
       "      <td>data/experiments/intersectional/female</td>\n",
       "      <td>data/experiments/gender/career</td>\n",
       "      <td>data/experiments/gender/family</td>\n",
       "      <td>-0.064636</td>\n",
       "      <td>0.623600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>data/experiments/intersectional/black-male</td>\n",
       "      <td>data/experiments/intersectional/white-male</td>\n",
       "      <td>data/experiments/gender/career</td>\n",
       "      <td>data/experiments/gender/family</td>\n",
       "      <td>0.023663</td>\n",
       "      <td>0.467100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>data/experiments/intersectional/white-male</td>\n",
       "      <td>data/experiments/intersectional/black-female</td>\n",
       "      <td>data/experiments/gender/career</td>\n",
       "      <td>data/experiments/gender/family</td>\n",
       "      <td>-0.024510</td>\n",
       "      <td>0.538700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>data/experiments/intersectional/white-male</td>\n",
       "      <td>data/experiments/intersectional/white-female</td>\n",
       "      <td>data/experiments/gender/career</td>\n",
       "      <td>data/experiments/gender/family</td>\n",
       "      <td>-0.167972</td>\n",
       "      <td>0.691600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>data/experiments/intersectional/white</td>\n",
       "      <td>data/experiments/intersectional/black</td>\n",
       "      <td>data/experiments/valence/pleasant</td>\n",
       "      <td>data/experiments/valence/unpleasant</td>\n",
       "      <td>0.136171</td>\n",
       "      <td>0.274600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>data/experiments/intersectional/white-male</td>\n",
       "      <td>data/experiments/intersectional/black-male</td>\n",
       "      <td>data/experiments/valence/pleasant</td>\n",
       "      <td>data/experiments/valence/unpleasant</td>\n",
       "      <td>0.029751</td>\n",
       "      <td>0.462600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>data/experiments/intersectional/white-male</td>\n",
       "      <td>data/experiments/intersectional/black-female</td>\n",
       "      <td>data/experiments/valence/pleasant</td>\n",
       "      <td>data/experiments/valence/unpleasant</td>\n",
       "      <td>-0.085097</td>\n",
       "      <td>0.597600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>data/experiments/intersectional/white-female</td>\n",
       "      <td>data/experiments/intersectional/white-male</td>\n",
       "      <td>data/experiments/valence/pleasant</td>\n",
       "      <td>data/experiments/valence/unpleasant</td>\n",
       "      <td>0.111622</td>\n",
       "      <td>0.359900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>data/experiments/intersectional/white-female</td>\n",
       "      <td>data/experiments/intersectional/black-male</td>\n",
       "      <td>data/experiments/valence/pleasant</td>\n",
       "      <td>data/experiments/valence/unpleasant</td>\n",
       "      <td>0.239512</td>\n",
       "      <td>0.225900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>data/experiments/intersectional/black-female</td>\n",
       "      <td>data/experiments/intersectional/black-male</td>\n",
       "      <td>data/experiments/valence/pleasant</td>\n",
       "      <td>data/experiments/valence/unpleasant</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.442200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>data/experiments/intersectional/white-female</td>\n",
       "      <td>data/experiments/intersectional/black-female</td>\n",
       "      <td>data/experiments/valence/pleasant</td>\n",
       "      <td>data/experiments/valence/unpleasant</td>\n",
       "      <td>0.379302</td>\n",
       "      <td>0.111600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>data/experiments/intersectional/female</td>\n",
       "      <td>data/experiments/intersectional/male</td>\n",
       "      <td>data/experiments/valence/pleasant</td>\n",
       "      <td>data/experiments/valence/unpleasant</td>\n",
       "      <td>0.071210</td>\n",
       "      <td>0.382600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               0  \\\n",
       "0          data/experiments/insect-flower/flower   \n",
       "1                  data/experiments/weapon/white   \n",
       "2                  data/experiments/weapon/white   \n",
       "3                   data/experiments/native/euro   \n",
       "4       data/experiments/asian/european-american   \n",
       "5                   data/experiments/weight/thin   \n",
       "6               data/experiments/skin-tone/light   \n",
       "7             data/experiments/disabled/disabled   \n",
       "8            data/experiments/presidents/kennedy   \n",
       "9            data/experiments/presidents/clinton   \n",
       "10              data/experiments/presidents/bush   \n",
       "11           data/experiments/presidents/lincoln   \n",
       "12        data/experiments/religion/christianity   \n",
       "13                data/experiments/sexuality/gay   \n",
       "14       data/experiments/race/european-american   \n",
       "15     data/experiments/arab-muslim/other-people   \n",
       "16                    data/experiments/age/young   \n",
       "17                  data/experiments/gender/male   \n",
       "18                  data/experiments/gender/male   \n",
       "19          data/experiments/intersectional/male   \n",
       "20    data/experiments/intersectional/white-male   \n",
       "21    data/experiments/intersectional/white-male   \n",
       "22    data/experiments/intersectional/white-male   \n",
       "23          data/experiments/intersectional/male   \n",
       "24    data/experiments/intersectional/black-male   \n",
       "25    data/experiments/intersectional/white-male   \n",
       "26    data/experiments/intersectional/white-male   \n",
       "27         data/experiments/intersectional/white   \n",
       "28    data/experiments/intersectional/white-male   \n",
       "29    data/experiments/intersectional/white-male   \n",
       "30  data/experiments/intersectional/white-female   \n",
       "31  data/experiments/intersectional/white-female   \n",
       "32  data/experiments/intersectional/black-female   \n",
       "33  data/experiments/intersectional/white-female   \n",
       "34        data/experiments/intersectional/female   \n",
       "\n",
       "                                               1  \\\n",
       "0          data/experiments/insect-flower/insect   \n",
       "1                  data/experiments/weapon/black   \n",
       "2                  data/experiments/weapon/black   \n",
       "3                 data/experiments/native/native   \n",
       "4          data/experiments/asian/asian-american   \n",
       "5                    data/experiments/weight/fat   \n",
       "6                data/experiments/skin-tone/dark   \n",
       "7                data/experiments/disabled/abled   \n",
       "8              data/experiments/presidents/trump   \n",
       "9              data/experiments/presidents/trump   \n",
       "10             data/experiments/presidents/trump   \n",
       "11             data/experiments/presidents/trump   \n",
       "12             data/experiments/religion/judaism   \n",
       "13           data/experiments/sexuality/straight   \n",
       "14        data/experiments/race/african-american   \n",
       "15      data/experiments/arab-muslim/arab-muslim   \n",
       "16                      data/experiments/age/old   \n",
       "17                data/experiments/gender/female   \n",
       "18                data/experiments/gender/female   \n",
       "19        data/experiments/intersectional/female   \n",
       "20    data/experiments/intersectional/black-male   \n",
       "21  data/experiments/intersectional/black-female   \n",
       "22  data/experiments/intersectional/white-female   \n",
       "23        data/experiments/intersectional/female   \n",
       "24    data/experiments/intersectional/white-male   \n",
       "25  data/experiments/intersectional/black-female   \n",
       "26  data/experiments/intersectional/white-female   \n",
       "27         data/experiments/intersectional/black   \n",
       "28    data/experiments/intersectional/black-male   \n",
       "29  data/experiments/intersectional/black-female   \n",
       "30    data/experiments/intersectional/white-male   \n",
       "31    data/experiments/intersectional/black-male   \n",
       "32    data/experiments/intersectional/black-male   \n",
       "33  data/experiments/intersectional/black-female   \n",
       "34          data/experiments/intersectional/male   \n",
       "\n",
       "                                      2  \\\n",
       "0     data/experiments/valence/pleasant   \n",
       "1          data/experiments/weapon/tool   \n",
       "2   data/experiments/weapon/tool-modern   \n",
       "3            data/experiments/native/us   \n",
       "4       data/experiments/asian/american   \n",
       "5     data/experiments/valence/pleasant   \n",
       "6     data/experiments/valence/pleasant   \n",
       "7     data/experiments/valence/pleasant   \n",
       "8     data/experiments/valence/pleasant   \n",
       "9     data/experiments/valence/pleasant   \n",
       "10    data/experiments/valence/pleasant   \n",
       "11    data/experiments/valence/pleasant   \n",
       "12    data/experiments/valence/pleasant   \n",
       "13    data/experiments/valence/pleasant   \n",
       "14    data/experiments/valence/pleasant   \n",
       "15    data/experiments/valence/pleasant   \n",
       "16    data/experiments/valence/pleasant   \n",
       "17      data/experiments/gender/science   \n",
       "18       data/experiments/gender/career   \n",
       "19      data/experiments/gender/science   \n",
       "20      data/experiments/gender/science   \n",
       "21      data/experiments/gender/science   \n",
       "22      data/experiments/gender/science   \n",
       "23       data/experiments/gender/career   \n",
       "24       data/experiments/gender/career   \n",
       "25       data/experiments/gender/career   \n",
       "26       data/experiments/gender/career   \n",
       "27    data/experiments/valence/pleasant   \n",
       "28    data/experiments/valence/pleasant   \n",
       "29    data/experiments/valence/pleasant   \n",
       "30    data/experiments/valence/pleasant   \n",
       "31    data/experiments/valence/pleasant   \n",
       "32    data/experiments/valence/pleasant   \n",
       "33    data/experiments/valence/pleasant   \n",
       "34    data/experiments/valence/pleasant   \n",
       "\n",
       "                                        3         4         5  \n",
       "0     data/experiments/valence/unpleasant -0.095075  0.647200  \n",
       "1          data/experiments/weapon/weapon  0.261615  0.318182  \n",
       "2   data/experiments/weapon/weapon-modern -0.321774  0.704545  \n",
       "3           data/experiments/native/world  0.106602  0.424100  \n",
       "4          data/experiments/asian/foreign -0.326956  0.737013  \n",
       "5     data/experiments/valence/unpleasant -0.175856  0.652800  \n",
       "6     data/experiments/valence/unpleasant  0.138021  0.400058  \n",
       "7     data/experiments/valence/unpleasant -0.001860  0.514286  \n",
       "8     data/experiments/valence/unpleasant -0.006637  0.510823  \n",
       "9     data/experiments/valence/unpleasant  0.140065  0.325758  \n",
       "10    data/experiments/valence/unpleasant  0.140525  0.358225  \n",
       "11    data/experiments/valence/unpleasant -0.173634  0.637446  \n",
       "12    data/experiments/valence/unpleasant -0.472518  0.805361  \n",
       "13    data/experiments/valence/unpleasant -0.044957  0.535600  \n",
       "14    data/experiments/valence/unpleasant -0.466431  0.778139  \n",
       "15    data/experiments/valence/unpleasant  0.218567  0.318200  \n",
       "16    data/experiments/valence/unpleasant  0.050492  0.468615  \n",
       "17   data/experiments/gender/liberal-arts  0.049749  0.411600  \n",
       "18         data/experiments/gender/family -0.028811  0.555200  \n",
       "19   data/experiments/gender/liberal-arts -0.056506  0.604600  \n",
       "20   data/experiments/gender/liberal-arts -0.246323  0.776700  \n",
       "21   data/experiments/gender/liberal-arts  0.044464  0.447700  \n",
       "22   data/experiments/gender/liberal-arts  0.238102  0.228700  \n",
       "23         data/experiments/gender/family -0.064636  0.623600  \n",
       "24         data/experiments/gender/family  0.023663  0.467100  \n",
       "25         data/experiments/gender/family -0.024510  0.538700  \n",
       "26         data/experiments/gender/family -0.167972  0.691600  \n",
       "27    data/experiments/valence/unpleasant  0.136171  0.274600  \n",
       "28    data/experiments/valence/unpleasant  0.029751  0.462600  \n",
       "29    data/experiments/valence/unpleasant -0.085097  0.597600  \n",
       "30    data/experiments/valence/unpleasant  0.111622  0.359900  \n",
       "31    data/experiments/valence/unpleasant  0.239512  0.225900  \n",
       "32    data/experiments/valence/unpleasant  0.046875  0.442200  \n",
       "33    data/experiments/valence/unpleasant  0.379302  0.111600  \n",
       "34    data/experiments/valence/unpleasant  0.071210  0.382600  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ieat.models import EmbeddingExtractor\n",
    "from ieat.utils import resize, tests_all, TestData\n",
    "from ieat.api import test\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms as T\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class RandomExtractor(EmbeddingExtractor):\n",
    "    n_px = 224\n",
    "    \n",
    "    def load_model(self):\n",
    "        model = torchvision.models.resnet50(pretrained=False)\n",
    "        # ends with avg pool layer\n",
    "#         print(list(model.children())[:-1])\n",
    "        self.model = nn.Sequential(*list(model.children())[:-1])\n",
    "    \n",
    "    def process_samples(self, image_paths, visualize=False):\n",
    "        x = resize(self.n_px, image_paths)\n",
    "        samples = x / 255 # normalize pixels values to -1 to +1\n",
    "        if visualize:\n",
    "            self.visualize(samples, image_paths)\n",
    "        return samples\n",
    "    \n",
    "    def _make_param_path(self):\n",
    "        return \"\"\n",
    "    \n",
    "    def _extract_context(self, samples, gpu, **extract_kwargs):\n",
    "        x = torch.reshape(torch.from_numpy(samples), (-1,3,224,224))\n",
    "        output = self.model(x.float())\n",
    "        return output.numpy().reshape((-1, 2048))\n",
    "\n",
    "extractor = RandomExtractor(\"random\", from_cache=False)\n",
    "results = []\n",
    "for test_data in tests_all:\n",
    "    print(f\"## {test_data.name} ##\")\n",
    "    categories = [\n",
    "        os.path.join('data/experiments', cat) for cat in (test_data.X, test_data.Y, test_data.A, test_data.B)\n",
    "    ]\n",
    "    effect, p = test(\n",
    "        *categories,\n",
    "        model=RandomExtractor(\"random\", from_cache=False),\n",
    "        model_type=\"random\",\n",
    "        model_params=(model_size,models_dir,color_clusters_dir,n_px)\n",
    "    )\n",
    "    results.append((*categories, effect, p))\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WH3YS_ytSHSw"
   },
   "source": [
    "### Detail View"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ePsWzNWpiTI"
   },
   "source": [
    "#### Weapons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xF-vbLVkWSLo"
   },
   "outputs": [],
   "source": [
    "from ieat.api import test\n",
    "\n",
    "test(\n",
    "    \"data/experiments/weapon/black\",\n",
    "    \"data/experiments/weapon/white\",\n",
    "    \"data/experiments/weapon/tool\",\n",
    "    \"data/experiments/weapon/weapon\",\n",
    "    model_type=\"openai\", \n",
    "    model_size=model_size,\n",
    "    models_dir=models_dir,\n",
    "    clusters_dir=color_clusters_dir,\n",
    "    n_px=n_px\n",
    "#     from_cache=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbZZ-m6QpiTM"
   },
   "source": [
    "#### Native"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wTs4pDDwpiTM"
   },
   "outputs": [],
   "source": [
    "test(\n",
    "    \"data/experiments/native/euro\",\n",
    "    \"data/experiments/native/native\",\n",
    "    \"data/experiments/native/us\",\n",
    "    \"data/experiments/native/world\",\n",
    "    model_type=\"openai\", \n",
    "    model_size=model_size,\n",
    "    models_dir=models_dir,\n",
    "    clusters_dir=color_clusters_dir,\n",
    "    n_px=n_px\n",
    "#     from_cache=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyrLx0cmpiTO"
   },
   "source": [
    "#### Asian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_nEjOV-QpiTP"
   },
   "outputs": [],
   "source": [
    "test(\n",
    "    \"data/experiments/asian/european-american\",\n",
    "    \"data/experiments/asian/asian-american\",\n",
    "    \"data/experiments/asian/american\",\n",
    "    \"data/experiments/asian/foreign\",\n",
    "    model_type=\"openai\", \n",
    "    model_size=model_size,\n",
    "    models_dir=models_dir,\n",
    "    clusters_dir=color_clusters_dir,\n",
    "    n_px=n_px\n",
    "#     from_cache=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8Wpc7vPxvhZ"
   },
   "source": [
    "#### Insect-Flower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y_dzK41F6Hso"
   },
   "outputs": [],
   "source": [
    "from ieat.api import test\n",
    "\n",
    "test(\n",
    "    \"data/experiments/insect-flower/flower\",\n",
    "    \"data/experiments/insect-flower/insect\",\n",
    "    \"data/experiments/valence/pleasant\",\n",
    "    \"data/experiments/valence/unpleasant\",\n",
    "    model_type=\"openai\", \n",
    "    model_size=model_size,\n",
    "    models_dir=models_dir,\n",
    "    clusters_dir=color_clusters_dir,\n",
    "    n_px=n_px,\n",
    "#     from_cache=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZalmenA0xvhb"
   },
   "source": [
    "#### Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ziXl8gaWxvhc"
   },
   "outputs": [],
   "source": [
    "from ieat.api import test\n",
    "\n",
    "test(\n",
    "    \"data/experiments/weight/thin\",\n",
    "    \"data/experiments/weight/fat\",\n",
    "    \"data/experiments/valence/pleasant\",\n",
    "    \"data/experiments/valence/unpleasant\",\n",
    "    model_type=\"openai\", \n",
    "    model_size=model_size,\n",
    "    models_dir=models_dir,\n",
    "    clusters_dir=color_clusters_dir,\n",
    "    n_px=n_px,\n",
    "#     from_cache=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7gYnQK4vxvhe"
   },
   "source": [
    "#### Skin-Tone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VFg-zm4Ixvhe"
   },
   "outputs": [],
   "source": [
    "from ieat.api import test\n",
    "\n",
    "test(\n",
    "    \"data/experiments/skin-tone/light\",\n",
    "    \"data/experiments/skin-tone/dark\",\n",
    "    \"data/experiments/valence/pleasant\",\n",
    "    \"data/experiments/valence/unpleasant\",\n",
    "    model_type=\"openai\", \n",
    "    model_size=model_size,\n",
    "    models_dir=models_dir,\n",
    "    clusters_dir=color_clusters_dir,\n",
    "    n_px=n_px,\n",
    "#     from_cache=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kqoUJ9_oxvhh"
   },
   "source": [
    "#### Disability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nLLGZcCRxvhh"
   },
   "outputs": [],
   "source": [
    "from ieat.api import test\n",
    "\n",
    "test(\n",
    "    \"data/experiments/disabled/disabled\",\n",
    "    \"data/experiments/disabled/abled\",\n",
    "    \"data/experiments/valence/pleasant\",\n",
    "    \"data/experiments/valence/unpleasant\",\n",
    "    model_type=\"openai\", \n",
    "    model_size=model_size,\n",
    "    models_dir=models_dir,\n",
    "    clusters_dir=color_clusters_dir,\n",
    "    n_px=n_px,\n",
    "#     from_cache=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VX-5Fpk2xvhl"
   },
   "source": [
    "#### Presidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qPYAHFFGxvhm"
   },
   "outputs": [],
   "source": [
    "from ieat.api import test\n",
    "\n",
    "test(\n",
    "    \"data/experiments/presidents/trump\",\n",
    "    \"data/experiments/presidents/kennedy\",\n",
    "    \"data/experiments/valence/pleasant\",\n",
    "    \"data/experiments/valence/unpleasant\",\n",
    "    model_type=\"openai\", \n",
    "    model_size=model_size,\n",
    "    models_dir=models_dir,\n",
    "    clusters_dir=color_clusters_dir,\n",
    "    n_px=n_px,\n",
    "#     from_cache=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zqSZmD4Rxvho"
   },
   "outputs": [],
   "source": [
    "from ieat.api import test\n",
    "\n",
    "test(\n",
    "    \"data/experiments/presidents/trump\",\n",
    "    \"data/experiments/presidents/clinton\",\n",
    "    \"data/experiments/valence/pleasant\",\n",
    "    \"data/experiments/valence/unpleasant\",\n",
    "    model_type=\"openai\", \n",
    "    model_size=model_size,\n",
    "    models_dir=models_dir,\n",
    "    clusters_dir=color_clusters_dir,\n",
    "    n_px=n_px,\n",
    "#     from_cache=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L6HNE0bvxvhq"
   },
   "outputs": [],
   "source": [
    "from ieat.api import test\n",
    "\n",
    "test(\n",
    "    \"data/experiments/presidents/trump\",\n",
    "    \"data/experiments/presidents/bush\",\n",
    "    \"data/experiments/valence/pleasant\",\n",
    "    \"data/experiments/valence/unpleasant\",\n",
    "    model_type=\"openai\", \n",
    "    model_size=model_size,\n",
    "    models_dir=models_dir,\n",
    "    clusters_dir=color_clusters_dir,\n",
    "    n_px=n_px,\n",
    "#     from_cache=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oTOxt8Y5xvhs"
   },
   "outputs": [],
   "source": [
    "from ieat.api import test\n",
    "\n",
    "test(\n",
    "    \"data/experiments/presidents/trump\",\n",
    "    \"data/experiments/presidents/lincoln\",\n",
    "    \"data/experiments/valence/pleasant\",\n",
    "    \"data/experiments/valence/unpleasant\",\n",
    "    model_type=\"openai\", \n",
    "    model_size=model_size,\n",
    "    models_dir=models_dir,\n",
    "    clusters_dir=color_clusters_dir,\n",
    "    n_px=n_px,\n",
    "#     from_cache=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ErIbgFMXxvhu"
   },
   "source": [
    "#### Religion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VvAe-DuUxvhu"
   },
   "outputs": [],
   "source": [
    "from ieat.api import test\n",
    "\n",
    "test(\n",
    "    \"data/experiments/religion/christianity\",\n",
    "    \"data/experiments/religion/judaism\",\n",
    "    \"data/experiments/valence/pleasant\",\n",
    "    \"data/experiments/valence/unpleasant\",\n",
    "    model_type=\"openai\", \n",
    "    model_size=model_size,\n",
    "    models_dir=models_dir,\n",
    "    clusters_dir=color_clusters_dir,\n",
    "    n_px=n_px,\n",
    "#     from_cache=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gt3GfXoYxvhw"
   },
   "source": [
    "#### Gender-Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2zs-M-ezxvhx"
   },
   "outputs": [],
   "source": [
    "from ieat.api import test\n",
    "\n",
    "test(\n",
    "    \"data/experiments/gender/science\",\n",
    "    \"data/experiments/gender/liberal-arts\",\n",
    "    \"data/experiments/gender/male\",\n",
    "    \"data/experiments/gender/female\",\n",
    "    model_type=\"openai\", \n",
    "    model_size=model_size,\n",
    "    models_dir=models_dir,\n",
    "    clusters_dir=color_clusters_dir,\n",
    "    n_px=n_px,\n",
    "#     from_cache=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BXbraCTvxvhy"
   },
   "source": [
    "#### Gender-Career"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wmICFKRhxvhz"
   },
   "outputs": [],
   "source": [
    "from ieat.api import test\n",
    "\n",
    "test(\n",
    "    \"data/experiments/gender/career\",\n",
    "    \"data/experiments/gender/family\",\n",
    "    \"data/experiments/gender/male\",\n",
    "    \"data/experiments/gender/female\",\n",
    "    model_type=\"openai\", \n",
    "    model_size=model_size,\n",
    "    models_dir=models_dir,\n",
    "    clusters_dir=color_clusters_dir,\n",
    "    n_px=n_px,\n",
    "#     from_cache=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_BI1Gxc4xvh1"
   },
   "source": [
    "#### Sexuality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6qhiTy3Rxvh2"
   },
   "outputs": [],
   "source": [
    "from ieat.api import test\n",
    "\n",
    "test(\n",
    "    \"data/experiments/sexuality/gay\",\n",
    "    \"data/experiments/sexuality/straight\",\n",
    "    \"data/experiments/valence/pleasant\",\n",
    "    \"data/experiments/valence/unpleasant\",\n",
    "    model_type=\"openai\", \n",
    "    model_size=model_size,\n",
    "    models_dir=models_dir,\n",
    "    clusters_dir=color_clusters_dir,\n",
    "    n_px=n_px,\n",
    "#     from_cache=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7VIIIFfpxvh3"
   },
   "source": [
    "#### Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fSuQzadOxvh4"
   },
   "outputs": [],
   "source": [
    "from ieat.api import test\n",
    "\n",
    "test(\n",
    "    \"data/experiments/race/african-american\",\n",
    "    \"data/experiments/race/european-american\",\n",
    "    \"data/experiments/valence/pleasant\",\n",
    "    \"data/experiments/valence/unpleasant\",\n",
    "    model_type=\"openai\", \n",
    "    model_size=model_size,\n",
    "    models_dir=models_dir,\n",
    "    clusters_dir=color_clusters_dir,\n",
    "    n_px=n_px,\n",
    "#     from_cache=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xA_AwxiKxvh5"
   },
   "source": [
    "#### Arab-Muslim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dAvppwCJxvh6"
   },
   "outputs": [],
   "source": [
    "from ieat.api import test\n",
    "\n",
    "test(\n",
    "    \"data/experiments/arab-muslim/other-people\",\n",
    "    \"data/experiments/arab-muslim/arab-muslim\",\n",
    "    \"data/experiments/valence/pleasant\",\n",
    "    \"data/experiments/valence/unpleasant\",\n",
    "    model_type=\"openai\", \n",
    "    model_size=model_size,\n",
    "    models_dir=models_dir,\n",
    "    clusters_dir=color_clusters_dir,\n",
    "    n_px=n_px,\n",
    "#     from_cache=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R-fdCFqQxvh8"
   },
   "source": [
    "#### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lVB-Wne_xvh8"
   },
   "outputs": [],
   "source": [
    "from ieat.api import test\n",
    "\n",
    "test(\n",
    "    \"data/experiments/age/young\",\n",
    "    \"data/experiments/age/old\",\n",
    "    \"data/experiments/valence/pleasant\",\n",
    "    \"data/experiments/valence/unpleasant\",\n",
    "    model_type=\"openai\", \n",
    "    model_size=model_size,\n",
    "    models_dir=models_dir,\n",
    "    clusters_dir=color_clusters_dir,\n",
    "    n_px=n_px,\n",
    "#     from_cache=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SpKVucUpxvh-"
   },
   "source": [
    "### Download Cached Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EfMcw700xvh-"
   },
   "outputs": [],
   "source": [
    "# to download from colab\n",
    "from google.colab import files\n",
    "\n",
    "!zip -r embeddings_colab.zip embeddings\n",
    "files.download(\"embeddings_colab.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GnG7quNVxviA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Image-GPT-Bias-HuggingFace.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "require": {
   "paths": {
    "buttons.colvis": "https://cdn.datatables.net/buttons/1.5.6/js/buttons.colVis.min",
    "buttons.flash": "https://cdn.datatables.net/buttons/1.5.6/js/buttons.flash.min",
    "buttons.html5": "https://cdn.datatables.net/buttons/1.5.6/js/buttons.html5.min",
    "buttons.print": "https://cdn.datatables.net/buttons/1.5.6/js/buttons.print.min",
    "chartjs": "https://cdnjs.cloudflare.com/ajax/libs/Chart.js/2.8.0/Chart",
    "d3": "https://d3js.org/d3.v5.min",
    "d3-array": "https://d3js.org/d3-array.v2.min",
    "datatables.net": "https://cdn.datatables.net/1.10.18/js/jquery.dataTables",
    "datatables.net-buttons": "https://cdn.datatables.net/buttons/1.5.6/js/dataTables.buttons.min",
    "datatables.responsive": "https://cdn.datatables.net/responsive/2.2.2/js/dataTables.responsive.min",
    "datatables.scroller": "https://cdn.datatables.net/scroller/2.0.0/js/dataTables.scroller.min",
    "datatables.select": "https://cdn.datatables.net/select/1.3.0/js/dataTables.select.min",
    "jszip": "https://cdnjs.cloudflare.com/ajax/libs/jszip/2.5.0/jszip.min",
    "moment": "https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.8.0/moment",
    "pdfmake": "https://cdnjs.cloudflare.com/ajax/libs/pdfmake/0.1.36/pdfmake.min",
    "vfsfonts": "https://cdnjs.cloudflare.com/ajax/libs/pdfmake/0.1.36/vfs_fonts"
   },
   "shim": {
    "buttons.colvis": {
     "deps": [
      "jszip",
      "datatables.net-buttons"
     ]
    },
    "buttons.flash": {
     "deps": [
      "jszip",
      "datatables.net-buttons"
     ]
    },
    "buttons.html5": {
     "deps": [
      "jszip",
      "datatables.net-buttons"
     ]
    },
    "buttons.print": {
     "deps": [
      "jszip",
      "datatables.net-buttons"
     ]
    },
    "chartjs": {
     "deps": [
      "moment"
     ]
    },
    "datatables.net": {
     "exports": "$.fn.dataTable"
    },
    "datatables.net-buttons": {
     "deps": [
      "datatables.net"
     ]
    },
    "pdfmake": {
     "deps": [
      "datatables.net"
     ]
    },
    "vfsfonts": {
     "deps": [
      "datatables.net"
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
